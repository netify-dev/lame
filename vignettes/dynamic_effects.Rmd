---
title: "Dynamic Effects in Longitudinal AME Models"
author: "Cassy Dorff, Tosin Salau, Shahryar Minhas"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Dynamic Effects in Longitudinal AME Models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

The `lame` package extends the Additive and Multiplicative Effects (AME) model to longitudinal network data through the introduction of dynamic effects. This vignette explains the theoretical foundation, implementation details, and practical usage of the `dynamic_uv` and `dynamic_ab` parameters.

## Theoretical Background

### Standard AME Model

The standard AME model decomposes network structure as:

$$y_{ij} = \beta'x_{ij} + a_i + b_j + u_i'v_j + \epsilon_{ij}$$

where:

- $\beta'x_{ij}$: Fixed effects of covariates
- $a_i$: Sender (row) effect for node $i$
- $b_j$: Receiver (column) effect for node $j$
- $u_i'v_j$: Multiplicative interaction between latent factors
- $\epsilon_{ij}$: Dyadic error term

### Dynamic Extensions

For longitudinal data with networks observed at times $t = 1, ..., T$, we extend the model to allow temporal evolution of effects.

#### Dynamic Multiplicative Effects (`dynamic_uv = TRUE`)

The latent factors evolve according to AR(1) processes:

$$U_{i,k,t} = \rho_{uv} U_{i,k,t-1} + \epsilon_{i,k,t}$$
$$V_{j,k,t} = \rho_{uv} V_{j,k,t-1} + \eta_{j,k,t}$$

where:

- $\epsilon_{i,k,t}, \eta_{j,k,t} \sim N(0, \sigma_{uv}^2)$
- $\rho_{uv} \in (0,1)$ controls temporal persistence
- $i,j$ index actors, $k$ indexes latent dimensions, $t$ indexes time

This specification allows actors' positions in latent social space to drift over time, capturing:

- Evolving community structure
- Time-varying homophily patterns
- Dynamic clustering and transitivity

#### Dynamic Additive Effects (`dynamic_ab = TRUE`)

The sender and receiver effects evolve as:

$$a_{i,t} = \rho_{ab} a_{i,t-1} + \epsilon_{i,t}$$
$$b_{j,t} = \rho_{ab} b_{j,t-1} + \eta_{j,t}$$

where:

- $\epsilon_{i,t}, \eta_{j,t} \sim N(0, \sigma_{ab}^2)$
- $\rho_{ab} \in (0,1)$ controls temporal smoothness

This captures:

- Time-varying activity levels (outdegree heterogeneity)
- Changing popularity (indegree heterogeneity)
- Life-cycle effects in social networks

## Prior Specifications

### For Dynamic Parameters

The package uses the following default priors:

**AR(1) coefficients:**

- $\rho_{uv} \sim \text{TruncNormal}(0.9, 0.1, 0, 1)$
- $\rho_{ab} \sim \text{TruncNormal}(0.8, 0.15, 0, 1)$

**Innovation variances:**

- $\sigma_{uv}^2 \sim \text{InverseGamma}(2, 1)$
- $\sigma_{ab}^2 \sim \text{InverseGamma}(2, 1)$

These can be customized via the `prior` argument:

```r
prior_custom <- list(
  rho_uv_mean = 0.95,    # Higher persistence for UV
  rho_uv_sd = 0.05,      # Tighter prior
  sigma_uv_shape = 3,    # Different variance prior
  sigma_uv_scale = 2
)
```

## Implementation Details

### Computational Efficiency

The dynamic effects are implemented in C++ via `Rcpp` and `RcppArmadillo`:

1. **Block sampling**: Updates are performed in blocks to improve mixing
2. **Sparse operations**: Exploits temporal structure for efficiency
3. **Memory optimization**:  about a 50% reduction compared to R implementation

### Algorithmic Details

The MCMC sampler alternates between:

1. **Forward filtering**: Compute predictive distributions $p(x_t | x_{1:t-1})$
2. **Backward sampling**: Sample from smoothed distribution $p(x_{1:T} | y_{1:T})$
3. **Parameter updates**: Sample $\rho$ and $\sigma^2$ given state sequences

This forward-filtering backward-sampling (FFBS) approach explores the posterior distribution.

## Practical Usage

### Basic Example

```r
library(lame)

# Simulate longitudinal network data
set.seed(123)
n <- 50  # actors
T <- 10  # time periods

# Generate networks (example with binary data)
Y_list <- list()
for(t in 1:T) {
  Y_t <- matrix(rbinom(n*n, 1, 0.1), n, n)
  diag(Y_t) <- NA
  Y_list[[t]] <- Y_t
}

# Fit model with dynamic effects
fit_dynamic <- lame(
  Y = Y_list,
  R = 2,                # 2-dimensional latent space
  dynamic_uv = TRUE,    # Dynamic latent factors
  dynamic_ab = TRUE,    # Dynamic additive effects
  family = "binary",
  burn = 1000,         # Longer burn-in recommended
  nscan = 5000,
  odens = 25
)
```

### Visualization

Plotting functions can illustrate temporal dynamics:

```r
# Plot latent positions at specific time
uv_plot(fit_dynamic, time_point = 5, plot_type = "snapshot")

# Plot trajectory of latent positions
uv_plot(fit_dynamic, plot_type = "trajectory", show_actors = c(1, 5, 10))

# Plot additive effects evolution
ab_plot(fit_dynamic, effect = "sender", plot_type = "trajectory")
```

### Model Selection

Choose between static and dynamic specifications based on:

1. **Model fit statistics**: Compare GOF, AIC, BIC
2. **Parameter estimates**: Check if $\rho$ significantly differs from 0
3. **Visual inspection**: Look for temporal patterns in residuals

```r
# Static model
fit_static <- lame(Y_list, R = 2, family = "binary")

# Dynamic UV only
fit_uv <- lame(Y_list, R = 2, dynamic_uv = TRUE, family = "binary")

# Dynamic AB only  
fit_ab <- lame(Y_list, R = 2, dynamic_ab = TRUE, family = "binary")

# Full dynamic
fit_full <- lame(Y_list, R = 2, dynamic_uv = TRUE, dynamic_ab = TRUE, family = "binary")

# Compare models
model_comparison <- data.frame(
  Model = c("Static", "Dynamic UV", "Dynamic AB", "Full Dynamic"),
  AIC = c(fit_static$AIC, fit_uv$AIC, fit_ab$AIC, fit_full$AIC),
  BIC = c(fit_static$BIC, fit_uv$BIC, fit_ab$BIC, fit_full$BIC)
)
```

## Convergence Diagnostics

Dynamic models typically require:

- Longer burn-in (≥ 1000 iterations)
- More samples (≥ 20000 post burn-in)
- Careful monitoring of $\rho$ and $\sigma^2$ parameters

```r
# Check effective sample sizes
library(coda)
mcmc_samples <- as.mcmc(fit_dynamic$BETA)
effectiveSize(mcmc_samples)

# Trace plots for dynamic parameters
par(mfrow = c(2, 2))
plot(fit_dynamic$rho_uv_samples, type = "l", main = "rho_uv trace")
plot(fit_dynamic$sigma_uv_samples, type = "l", main = "sigma_uv trace")
plot(fit_dynamic$rho_ab_samples, type = "l", main = "rho_ab trace")
plot(fit_dynamic$sigma_ab_samples, type = "l", main = "sigma_ab trace")
```

## References

1. **Sewell, D. K., & Chen, Y. (2015)**. Latent space models for dynamic networks. *Journal of the American Statistical Association*, 110(512), 1646-1657.

2. **Durante, D., & Dunson, D. B. (2014)**. Nonparametric Bayes dynamic modeling of relational data. *Biometrika*, 101(4), 883-898.

## Appendix: Mathematical Details

### Posterior Distributions

For the AR(1) parameters, the full conditionals are:

$$p(\rho | \cdot) \propto p(\rho) \prod_{t=2}^T p(x_t | x_{t-1}, \rho, \sigma^2)$$

$$p(\sigma^2 | \cdot) \sim \text{IG}\left(\alpha + \frac{n(T-1)}{2}, \beta + \frac{1}{2}\sum_{t=2}^T ||x_t - \rho x_{t-1}||^2\right)$$

### Identification

The dynamic effects are identified through:
1. Temporal ordering constraints
2. Stationarity assumption ($|\rho| < 1$)
3. Initial state distribution $x_1 \sim N(0, \sigma^2/(1-\rho^2))$

### Computational Complexity

- **Time complexity**: $O(n^2 RT)$ per iteration
- **Space complexity**: $O(nRT)$ for storage
- **Mixing time**: Typically $O(\log T)$ with good initialization