% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/simulate.ame.R
\name{simulate.ame}
\alias{simulate.ame}
\title{Simulate networks from a fitted AME model}
\usage{
\method{simulate}{ame}(
  object,
  nsim = 100,
  seed = NULL,
  newdata = NULL,
  burn_in = 0,
  thin = 1,
  return_latent = FALSE,
  ...
)
}
\arguments{
\item{object}{fitted model object of class "ame"}

\item{nsim}{number of networks to simulate (default: 100)}

\item{seed}{random seed for reproducibility}

\item{newdata}{optional list containing new covariate data:
\describe{
\item{Xdyad}{dyadic covariates (n x n x p array or nA x nB x p for bipartite)}
\item{Xrow}{row/sender covariates (n x p matrix or nA x p for bipartite)}
\item{Xcol}{column/receiver covariates (n x p matrix or nB x p for bipartite)}
}
If NULL, uses covariates from original model fit}

\item{burn_in}{number of initial MCMC samples to discard (default: 0, assumes
burn-in already removed)}

\item{thin}{thinning interval for MCMC samples (default: 1, use every sample)}

\item{return_latent}{logical: return latent Z matrices in addition to Y? (default: FALSE)}

\item{...}{additional arguments (not currently used)}
}
\value{
A list with components:
\describe{
\item{Y}{list of nsim simulated networks in the same format as the original data}
\item{Z}{if return_latent=TRUE, list of nsim latent Z matrices}
\item{family}{the family of the model (binary, normal, etc.)}
\item{mode}{network mode (unipartite or bipartite)}
}
}
\description{
Generates multiple network realizations from the posterior distribution of
a fitted AME model. This function performs posterior predictive simulation
by drawing from the full joint posterior distribution of model parameters,
thereby propagating parameter uncertainty into the simulated networks.
}
\details{
\strong{Mathematical Framework:}

The AME model represents networks through a latent variable framework:
\deqn{Y_{ij} \sim F(Z_{ij})}
where F is the observation model (e.g., probit for binary) and Z is the latent network:
\deqn{Z_{ij} = \beta^T x_{ij} + a_i + b_j + u_i^T v_j + \epsilon_{ij}}

Components:
\itemize{
\item \eqn{\beta}: regression coefficients for dyadic/nodal covariates
\item \eqn{a_i, b_j}: additive sender and receiver random effects
\item \eqn{u_i, v_j}: multiplicative latent factors (dimension R)
\item \eqn{\epsilon_{ij}}: dyadic random effects with correlation \eqn{\rho}
}

\strong{Uncertainty Quantification Process:}

For each simulated network k = 1, ..., nsim:
\enumerate{
\item \strong{Parameter Sampling:} Draw parameter set \eqn{\theta^{(k)}} from MCMC chains:
\itemize{
\item Sample iteration s uniformly from stored MCMC samples
\item Extract \eqn{\beta^{(s)}}, variance components \eqn{(v_a^{(s)}, v_b^{(s)}, v_e^{(s)}, \rho^{(s)})}
}
\item \strong{Random Effects Generation:} Sample new random effects from posterior distributions:
\itemize{
\item \eqn{a_i^{(k)} \sim N(0, v_a^{(s)})} for i = 1, ..., n (row effects)
\item \eqn{b_j^{(k)} \sim N(0, v_b^{(s)})} for j = 1, ..., m (column effects)
\item Note: We sample fresh from the posterior variance rather than using
point estimates to properly propagate uncertainty
}
\item \strong{Latent Network Construction:} Build expected latent positions:
\deqn{E[Z_{ij}^{(k)}] = \beta^{(s)T} x_{ij} + a_i^{(k)} + b_j^{(k)} + \hat{u}_i^T \hat{v}_j}
where \eqn{\hat{u}_i, \hat{v}_j} are posterior mean latent factors
\item \strong{Dyadic Correlation:} Add correlated noise structure:
\deqn{Z_{ij}^{(k)} = E[Z_{ij}^{(k)}] + \epsilon_{ij}^{(k)}}
where \eqn{\epsilon} has covariance structure:
\deqn{Cov(\epsilon_{ij}, \epsilon_{ji}) = \rho^{(s)} v_e^{(s)}}
\deqn{Var(\epsilon_{ij}) = v_e^{(s)}}
\item \strong{Observation Model:} Generate observed network based on family:
\itemize{
\item Binary: \eqn{Y_{ij}^{(k)} = I(Z_{ij}^{(k)} > 0)}
\item Normal: \eqn{Y_{ij}^{(k)} = Z_{ij}^{(k)}}
\item Poisson: \eqn{Y_{ij}^{(k)} \sim Poisson(\exp(Z_{ij}^{(k)}))}
\item Other families use appropriate link functions
}
}

\strong{Sources of Uncertainty:}

The simulation captures three types of uncertainty:
\enumerate{
\item \strong{Parameter uncertainty:} Different MCMC samples yield different \eqn{\beta, v_a, v_b, v_e, \rho}
\item \strong{Random effect uncertainty:} Fresh draws from \eqn{N(0, v_a), N(0, v_b)} for each simulation
\item \strong{Dyadic uncertainty:} Correlated random noise \eqn{\epsilon_{ij}}
}

This approach provides proper posterior predictive distributions that account
for all sources of uncertainty in the model. The variation across simulated
networks reflects our posterior uncertainty about the data generating process.

\strong{Limitations:}

Currently, multiplicative effects (U, V) use posterior means rather than
sampling from their full posterior. For complete uncertainty quantification,
one would need to store and sample from the full MCMC chains of these
latent factors, which would require substantial additional memory.

\strong{Symmetric Networks:}

For symmetric networks, the model enforces \eqn{a_i = b_i} and \eqn{u_i = v_i},
and the latent matrix Z is symmetrized before generating observations.
}
\examples{
\dontrun{
# Fit a model
data(YX_bin)
fit <- ame(YX_bin$Y, YX_bin$X, burn=100, nscan=500, family="binary")

# Simulate 50 networks from posterior
sims <- simulate(fit, nsim=50)

# With new covariates
new_X <- array(rnorm(dim(YX_bin$X)[1] * dim(YX_bin$X)[2] * dim(YX_bin$X)[3]),
               dim=dim(YX_bin$X))
sims_new <- simulate(fit, nsim=50, newdata=list(Xdyad=new_X))
}

}
\author{
Shahryar Minhas
}
